```{r}
library(textir)
library(maptpx)
library(wordcloud)
library(rddtools)
library(glmnet)
```

<!-- This hoemwork tests on: -->
<!-- 1. RDD (Regression Discontinuity Deisng); -->
<!-- 2. K-Means and how to select the best k; -->
<!-- 3. Topic model. -->

```{r}
## Problem Set 1.1
class <- read.csv("class.csv")

# Scatter Plot
plot(class$class_size, class$mean_test_score) + abline(v = 30)

# correlation coefficient
cor(class$class_size, class$mean_test_score)
```



```{r}
## Problem Set 1.3
classsize <- class$class_size
u_test_score <- class$mean_test_score
data <- rdd_data(u_test_score, classsize, cutpoint = 30)
rdd_mod <- rdd_reg_lm(rdd_object = data, 
                      slope = "same")

# Summarize the regression. D is the variable we are interested in.
summary(rdd_mod)
```

```{r}
## Problem Set 2.1
load("congress.RData")

set.seed(233)
k_pool <- c(5, 10, 15, 20, 25)
congress109Counts_scaled <- scale(as.matrix( congress109Counts/rowSums(congress109Counts) ))

result <- lapply(X=k_pool, FUN=kmeans, x=congress109Counts_scaled, nstart = 5)
for(i in 1:length(k_pool)){
    cat("k =", k_pool[i], ", sizes are:", result[[i]]$size, "\n")
}

#potential issue: heavily correlated topics
#cor(congress109Counts)[cor(congress109Counts) < 1 & cor(congress109Counts) > 0.8]
```
```{r}
## Problem Set 2.2
# Use BIC to choose the optimal K
kmeansBIC <- function(fit){
    m = ncol(fit$centers)
    n = length(fit$cluster)
    k = nrow(fit$centers)
    D = fit$tot.withinss
    return(D + log(n)*m*k)
}

# try a list of cancidate K values
k_pool2 <- seq(3, 60)
result_2 <- lapply(X=k_pool2, FUN=kmeans, x=congress109Counts_scaled, nstart = 5, iter.max = 20)

# summarize the result, and find the optimal solution
k_list <- c()
BIC_list <- c()
deviance_list <- c()
for(i in 1:length(k_pool2)){
    k <- k_pool2[i]
    k_list <- c(k_list, k)
    BIC <- kmeansBIC(result_2[[i]])
    BIC_list <- c(BIC_list, BIC)
    deviance <- result_2[[i]]$tot.withinss
    deviance_list <- c(deviance_list, deviance)
    cat("k =", k, "BIC =", BIC, "\n")
    if(i == length(k_pool2)){
        cat("\nMinimum BIC is:", min(BIC_list))
        cat("Optimal k is:", k_list[BIC_list == min(BIC_list)], "\n")
        result_optimized <- kmeans(congress109Counts_scaled, nstart = 5, iter.max = 20, centers = k_list[BIC_list == min(BIC_list)])
        print(tapply(congress109Ideology$party, result_optimized$cluster, table))
    }
}

#top 10 keywords in each cluster of the optimal kmeans model
print(apply(result_optimized$centers,1,function(c) colnames(congress109Counts_scaled)[order(-c)[1:10]]))

# Use elbow curve method to choose the optimal K
plot(x = k_list, y = deviance_list)
print("The elbow indicates about k = 6")
```

```{r}
## Problem Set 2.3
fs <- scale(as.matrix(congress109Counts/rowSums(congress109Counts) ))
kmfs <- kmeans(fs,4) 

print(apply(kmfs$centers,1,function(c) colnames(fs)[order(-c)[1:10]]))

## convert from a Matrix to a `slam' simple_triplet_matrix
x <- as.simple_triplet_matrix(congress109Counts)

## choosing the number of topics with Bayes factor
tpcs <- topics(x, K=5*(1:5), verb=10)

## we choose 10 topics with Bayes factor at last

## the topic word prob over marginal word prob.
summary(tpcs, n=10) 
```

```{r}
## rank terms within each topic based on their probability, for example, the first two topics
rownames(tpcs$theta)[order(tpcs$theta[,1], decreasing=TRUE)[1:10]]
rownames(tpcs$theta)[order(tpcs$theta[,2], decreasing=TRUE)[1:10]]
```

```{r}
## visualize words within the first topic based on their probability, and only show those with probability > 0.008
wordcloud(row.names(tpcs$theta), 
          freq=tpcs$theta[,1], min.freq=0.008, col="maroon")

## visualize words within the first 2 topic based on their probability, and only show those with probability > 0.008
wordcloud(row.names(tpcs$theta), 
          freq=tpcs$theta[,2], min.freq=0.008, col="navy")
```


```{r}
## Problem Set 2.4
# delete independents observations
congress109Counts_slam <- as.simple_triplet_matrix(congress109Counts)
topic_list <- topics(congress109Counts_slam[which(congress109Ideology$party != 'I'), ], K = seq(2, 30), verb = 5)
party <- factor(congress109Ideology[which(congress109Ideology$party != 'I'), "party"])

# binomial regression
tpcreg <- glmnet(topic_list$omega, party, family = "binomial")
# number of stars up or down for moving up 10% weight in that topic
drop(coef(tpcreg))*0.1
regtopics.cv <- cv.glmnet(topic_list$omega, party, family = "binomial")

## give it the word %s as inputs
x <- 100 * congress109Counts / rowSums(congress109Counts)
x <- x[which(congress109Ideology$party != 'I'), ]
regwords.cv <- cv.glmnet(x, party, family = "binomial")

par(mfrow=c(1,2))
plot(regtopics.cv)
mtext("topic regression", font=2, line=2)
plot(regwords.cv)
mtext("bigram regression", font=2, line=2)
```


```{r}
# max OOS R^2s
max(1-regtopics.cv$cvm/regtopics.cv$cvm[1])
max(1-regwords.cv$cvm/regwords.cv$cvm[1])
```

```{r}
# topic model and phrase percentage regression on repshare

# use original complete data
topic_list <- topics(congress109Counts_slam, K = seq(2, 30), verb = 5)
repshare <- congress109Ideology[,"repshare"]

# linear regression
tpcreg <- gamlr(topic_list$omega, repshare)
# number of stars up or down for moving up 10% weight in that topic
drop(coef(tpcreg))*0.1
regtopics.cv <- cv.glmnet(topic_list$omega, repshare)

## give it the word %s as inputs
x <- 100 * congress109Counts / rowSums(congress109Counts)
regwords.cv <- cv.glmnet(x, repshare)

par(mfrow=c(1,2))
plot(regtopics.cv)
mtext("topic regression", font=2, line=2)
plot(regwords.cv)
mtext("bigram regression", font=2, line=2)
```


```{r}
# max OOS R^2s
max(1-regtopics.cv$cvm/regtopics.cv$cvm[1])
max(1-regwords.cv$cvm/regwords.cv$cvm[1])
```

